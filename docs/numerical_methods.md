# Numerical Methods

GANDALF uses **pseudo-spectral methods** in space and a **specialized integrating factor timestepper** for temporal evolution. This document explains the numerical algorithms and implementation choices.

## Overview

| Component | Method | Key Feature |
|-----------|--------|-------------|
| **Spatial discretization** | 3D Fourier spectral | Spectral accuracy (exponential convergence) |
| **Time integration** | GANDALF integrating factor + RK2 | Exact linear propagation, 2nd-order nonlinear |
| **Dealiasing** | 2/3 rule | Prevents aliasing errors in nonlinear terms |
| **Poisson solver** | Direct (Fourier space) | kÂ²Ï† = -kâŠ¥Â²Aâˆ¥ solved exactly |
| **Dissipation** | Normalized hyper-dissipation | Resolution-independent parameters |
| **Kinetic physics** | Hermite moment expansion | Captures Landau damping, phase mixing |

## Spectral Method

### Why Spectral?

Spectral methods represent fields as sums of basis functions (Fourier modes):

```
f(x,y,z) = Î£ fÌ‚(kx,ky,kz) exp(i(kxÂ·x + kyÂ·y + kzÂ·z))
```

**Advantages:**
- **Spectral accuracy:** Error decreases exponentially with resolution (vs algebraically for finite differences)
- **Exact derivatives:** âˆ‚f/âˆ‚x = Î£ (ikx) fÌ‚(kx,ky,kz) exp(...)
- **Easy Poisson solver:** âˆ‡Â²Ï† = Ï‰ â†’ -kÂ²Ï†Ì‚ = Ï‰Ì‚ â†’ Ï†Ì‚ = -Ï‰Ì‚/kÂ²
- **Clean dealiasing:** 2/3 rule exactly removes aliasing

**Disadvantages:**
- Requires periodic boundary conditions (not suitable for walls or open boundaries)
- Memory intensive (all modes stored globally)
- Load balancing on parallel machines more complex than domain decomposition

For KRMHD turbulence in periodic boxes, spectral methods are ideal.

### 3D Fourier Decomposition

GANDALF decomposes fields in all three directions:

```
f(x,y,z) â†’ fÌ‚(kx, ky, kz)
```

**Wavenumbers:**
```
kx = (2Ï€/Lx) Ã— nx,  nx = 0, 1, ..., Nx/2 (rfft format)
ky = (2Ï€/Ly) Ã— ny,  ny = -Ny/2, ..., Ny/2-1
kz = (2Ï€/Lz) Ã— nz,  nz = -Nz/2, ..., Nz/2-1
```

### Box Size and Time Normalization

**A subtle but critical point:** The box sizes Lx, Ly, Lz can be set independently, providing separate control over spatial and temporal normalizations.

**Perpendicular box sizes (Lx, Ly)** control perpendicular wavenumber spacing:
```
kâŠ¥ = âˆš(kxÂ² + kyÂ²) = (2Ï€/LâŠ¥) Ã— âˆš(nxÂ² + nyÂ²)
```

**Parallel box size (Lz)** controls BOTH:
1. Parallel wavenumber spacing: kz = (2Ï€/Lz) Ã— nz
2. AlfvÃ©n time normalization: **Ï„_A = Lz/v_A**

This means **changing Lz affects both spatial resolution in z AND the time normalization** - a common source of confusion.

**Common normalization conventions:**

| Convention | Lx, Ly | Lz | kâŠ¥ | Ï„_A | Use case |
|------------|--------|----|----|-----|----------|
| **Unit box** (thesis) | 1.0 | 1.0 | 2Ï€n | 1.0 | Match original GANDALF thesis |
| **Integer k** (code default) | 2Ï€ | 2Ï€ | n | 2Ï€/v_A | Clean wavenumber indexing |
| **Mixed** | 2Ï€ | 1.0 | n | 1.0 | Turbulence studies (integer kâŠ¥, unit time) |

*(Assumes v_A = 1 for simplicity. For general v_A, multiply Ï„_A values by 1/v_A. For example, with v_A = 2, the "integer k" convention gives Ï„_A = Ï€.)*

**Practical implications:**

1. **For turbulence studies:** Use Lx = Ly = 2Ï€ for integer perpendicular wavenumbers (kâŠ¥ = 1, 2, 3, ...)
   - Makes forcing at "k=2" intuitive (literally mode number 2)
   - Inertial range kâŠ¥ âˆˆ [1, 10] corresponds to mode numbers [1, 10]

2. **For time normalization:** Set Lz based on desired Ï„_A (with v_A = 1):
   - Lz = 1.0 â†’ Ï„_A = 1.0 (one AlfvÃ©n time = 1.0 simulation time units)
   - Lz = 2Ï€ â†’ Ï„_A = 2Ï€ â‰ˆ 6.28 (one AlfvÃ©n time = 2Ï€ simulation time units)

3. **For benchmarks:** Match the reference convention exactly
   - Orszag-Tang vortex: Lx = Ly = Lz = 1.0 (thesis convention)
   - Energy oscillation period: ~2 Ï„_A = ~2.0 simulation time units

**Common pitfall:**

âš ï¸ **Doubling Lz has two effects:**
- âœ… Halves kâˆ¥ resolution (modes become closer in kâˆ¥-space)
- âš ï¸ Doubles AlfvÃ©n crossing time Ï„_A (time runs twice as slow in AlfvÃ©n units!)

When comparing runs with different Lz, must account for both effects. A wave with kz = 2Ï€/Lz will have the same physical wavelength, but different mode number nz and different propagation time.

**Example:** Consider an AlfvÃ©n wave with kz = 1 (mode number nz = 1):

| Lz | kz (mode 1) | Wavelength Î»z | Propagation time (1 Î»z) |
|----|-------------|---------------|-------------------------|
| 1.0 | 2Ï€ â‰ˆ 6.28 | 1.0 | Ï„_A = 1.0 |
| 2Ï€ | 1.0 | 2Ï€ â‰ˆ 6.28 | Ï„_A = 2Ï€ â‰ˆ 6.28 |

Same mode number, different physical k and time!

**Best practice:** Choose normalization at the start and document it clearly. When in doubt, use the code default (Lx = Ly = Lz = 2Ï€) for consistency.

ğŸ“– **See [Running Simulations: Understanding the Code](running_simulations.md#understanding-the-code)** for practical examples using these normalization conventions.

**Grid structure:** For Nx Ã— Ny Ã— Nz real-space grid:
- **Real space:** (Nz, Ny, Nx) array, real values
- **Fourier space:** (Nz, Ny, Nx//2+1) array, complex values

### rfft Format (Memory Efficiency)

Since real fields satisfy f(-k) = f*(k) (Hermitian symmetry), we only store half of the kx modes:

```python
import jax.numpy as jnp

# Forward transform (real â†’ complex)
f_real = ...  # Shape: (Nz, Ny, Nx)
f_hat = jnp.fft.rfftn(f_real, axes=(0, 1, 2))  # Shape: (Nz, Ny, Nx//2+1)

# Inverse transform (complex â†’ real)
f_real_recovered = jnp.fft.irfftn(f_hat, s=(Nz, Ny, Nx))
```

**Memory savings:** Factor of ~2 (store Nx//2+1 instead of Nx modes in x-direction).

**Reality condition:** Enforced automatically by `irfftn`, but must be maintained manually when:
- Adding forcing directly in Fourier space
- Modifying specific modes
- Setting initial conditions

**Special planes:**
- `kx=0` plane: Must be real (imaginary part automatically zeroed by `irfftn`)
- `kx=Nyquist` plane (if Nx even): Must also be real

### Derivative Operators

Spatial derivatives are **exact** in Fourier space:

```
âˆ‚f/âˆ‚x â†” iÂ·kxÂ·fÌ‚
âˆ‚f/âˆ‚y â†” iÂ·kyÂ·fÌ‚
âˆ‚f/âˆ‚z â†” iÂ·kzÂ·fÌ‚
```

**Implementation:**
```python
from krmhd.spectral import derivative_x, derivative_y, derivative_z

df_dx = derivative_x(f_hat, grid)  # Returns iÂ·kxÂ·fÌ‚
df_dy = derivative_y(f_hat, grid)  # Returns iÂ·kyÂ·fÌ‚
df_dz = derivative_z(f_hat, grid)  # Returns iÂ·kzÂ·fÌ‚
```

**Laplacian:**
```python
laplacian = grid.k_squared * f_hat  # âˆ‡Â²f â†” -kÂ²fÌ‚
```

For perpendicular Laplacian only (KRMHD uses this):
```python
laplacian_perp = grid.k_perp_squared * f_hat  # âˆ‡âŠ¥Â²f â†” -(kxÂ²+kyÂ²)fÌ‚
```

**No numerical diffusion:** Unlike finite differences, spectral derivatives have zero numerical viscosity.

### Exact Treatment of Linear Physics

**A key advantage over finite-difference methods:** The combination of spectral derivatives and the integrating factor method means **linear physics is captured analytically**, not through numerical approximation.

**What "exact" means in practice:**

1. **AlfvÃ©n wave dispersion relation:** Ï‰ = kâˆ¥v_A is satisfied **exactly per timestep**
   - No numerical dispersion (phase speed errors) from spatial discretization
   - Waves propagate at precisely the correct speed for all wavelengths
   - No grid-scale artifacts (wave on diagonal = wave on axis)
   - **Short-term (1 wave period):** <1% energy drift (validates linear wave propagation)
   - **Long-term (100s of Ï„_A):** <0.01% drift (validates cumulative roundoff control)

2. **Landau damping rates:** Computed accurately with kinetic Hermite expansion
   - Kinetic effects (resonance, phase mixing) captured via moment hierarchy
   - Critical for validation against analytical theory
   - Practical accuracy: ~10â»Â¹â° relative error in kinetic energy balance

3. **Wave polarization:** Preserved exactly
   - No spurious coupling between modes
   - Slow modes remain passive (no artificial back-reaction)

**Contrast with finite difference methods:**

| Property | Finite Differences | Spectral + Integrating Factor |
|----------|-------------------|-------------------------------|
| **Phase speed error** | ~ (kÎ”x)Â² (2nd-order) | 0 per timestep (analytical) |
| **Numerical dispersion** | Ï‰_numerical â‰  Ï‰_exact | Ï‰_numerical = Ï‰_exact (per step) |
| **Numerical diffusion** | Spurious damping | None (inviscid conserves energy) |
| **Grid anisotropy** | Diagonal â‰  Axis | Isotropic (all directions equal) |
| **Timestep for stability** | Î”t < Î”x/v_A (wave CFL) | Î”t limited by nonlinear terms only |

**Why this matters:**

- **Validation tests** achieve high accuracy in energy conservation (not ~10â»â¶ as with FD)
  - Short-term: <1% over wave periods
  - Long-term: <0.01% over 100s of Ï„_A (~10â»Â¹â° relative error in energy balance)
- **Phase error accumulation** is minimal (analytical integration per timestep)
- **Benchmarking** can distinguish code bugs from numerical discretization errors

**Technical implementation:**

1. **Spectral derivatives** (Fourier space multiplication):
   ```
   âˆ‚f/âˆ‚x = iÂ·kxÂ·fÌ‚  (analytically exact, no truncation error)
   ```

2. **Integrating factor** (Fourier space phase shift):
   ```
   zÂ±(t+Î”t) = exp(Â±iÂ·kzÂ·v_AÂ·Î”t) Â· zÂ±(t)  (analytically exact for linear term)
   ```

3. **Combined effect:** Linear propagation term is integrated analytically, not numerically approximated.

**When exactness breaks down:**

- **Nonlinear terms:** Approximated with RK2 (2nd-order in Î”t, not exact)
- **Dealiasing truncation:** Modes beyond 2/3 k_Nyquist are removed (intentional)
- **Floating-point roundoff:** Accumulates over many timesteps (~10â»Â¹â° typical after full period)
- **FFT precision:** Practical derivative accuracy ~10â»âµ after FFT roundtrip
- **Hermite truncation:** Finite M moments (kinetic closure approximation)

**Validation consequence:** Linear wave tests should achieve <1% energy drift over full wave period. If you see >10% drift, there's likely a bug in the implementation.

## Dealiasing (2/3 Rule)

### Why Dealiasing?

Nonlinear terms like {f,g} involve products in real space:

```
h(x) = f(x) Â· g(x)
```

**Problem:** If f has modes up to k_max and g has modes up to k_max, their product h has modes up to 2Â·k_max. On a grid with Nyquist frequency k_Nyquist = N/2, modes beyond k_Nyquist **wrap around** (aliasing) and corrupt lower modes.

**Example:**
- Grid: N=64 â†’ k_Nyquist = 32
- Mode k=30 Ã— Mode k=30 = Mode k=60
- But k=60 > k_Nyquist â†’ wraps to k = 60 - 64 = -4 (aliases to k=4)

This causes spurious energy transfer and violates conservation laws.

### The 2/3 Rule

**Solution:** Keep only modes with |k| â‰¤ k_max = (2/3)Â·k_Nyquist.

For N=64:
- k_Nyquist = 32
- k_max = 21 (after dealiasing)
- Products: k=21 Ã— k=21 = k=42 â‰¤ 2Â·k_max = 42 âœ“ (no aliasing)

**Implementation:**
```python
from krmhd.spectral import SpectralGrid3D

grid = SpectralGrid3D(Nx=64, Ny=64, Nz=64, Lx=2*np.pi, Ly=2*np.pi, Lz=2*np.pi)

# Compute nonlinear term (e.g., Poisson bracket)
f_hat = ...
g_hat = ...

# Transform to real space, multiply, transform back
f_real = jnp.fft.irfftn(f_hat, s=(grid.Nz, grid.Ny, grid.Nx))
g_real = jnp.fft.irfftn(g_hat, s=(grid.Nz, grid.Ny, grid.Nx))
product_real = f_real * g_real
product_hat = jnp.fft.rfftn(product_real)

# CRITICAL: Apply dealiasing mask
product_hat_dealiased = grid.dealias(product_hat)
```

**Dealiasing mask:** Sets to zero all modes with:
```
|kx| > (2/3)Â·(Nx/2)  OR  |ky| > (2/3)Â·(Ny/2)  OR  |kz| > (2/3)Â·(Nz/2)
```

**Performance:** Dealiasing is cheap (just a mask multiplication), but FFTs dominate cost.

**Importance:** Without dealiasing, energy grows spuriously and simulations blow up.

## Poisson Solver

KRMHD requires solving for the stream function Ï† from the vorticity:

```
âˆ‡âŠ¥Â²Ï† = Ï‰ = -âˆ‡âŠ¥Â²Aâˆ¥
```

In Fourier space, this is trivial:

```
-kâŠ¥Â² Ï†Ì‚ = -kâŠ¥Â² Ã‚âˆ¥
â†’ Ï†Ì‚ = Ã‚âˆ¥
```

But more generally, for âˆ‡Â²Ï† = Ï‰:

```
-kÂ² Ï†Ì‚ = Ï‰Ì‚
â†’ Ï†Ì‚ = -Ï‰Ì‚ / kÂ²
```

**Singularity at k=0:** The k=0 mode represents the spatial mean. For Poisson equation, the mean is arbitrary (set to zero):

```python
def poisson_solve_3d(omega_hat, grid):
    """Solve âˆ‡Â²Ï† = Ï‰ for Ï†."""
    phi_hat = jnp.where(
        grid.k_squared > 0,
        -omega_hat / grid.k_squared,
        0.0  # Set k=0 mode to zero (mean = 0)
    )
    return phi_hat
```

**No iteration needed:** Direct solve in one step (advantage of spectral methods).

**In KRMHD:** Elsasser formulation eliminates need for Poisson solve in timestepping. But diagnostics (computing Ï† from zÂ±) use it:

```python
from krmhd.physics import elsasser_to_physical

phi, A_parallel = elsasser_to_physical(z_plus, z_minus)
# Uses Ï† = (zâº + zâ»)/2 and Aâˆ¥ = (zâº - zâ»)/2 (no Poisson solve!)
```

## Time Integration: GANDALF Method

### The Challenge

KRMHD equations have both **linear** and **nonlinear** terms:

```
âˆ‚zÂ±/âˆ‚t = Â±iÂ·kzÂ·zÂ± + NÂ±[zÂ±,zâˆ“] - dissipation
         \_______/   \__________/
          Linear      Nonlinear
```

**Linear term:** Represents AlfvÃ©n wave propagation (oscillatory, frequency Ï‰ = kzÂ·v_A)

**Problem with standard RK methods:**
- Standard RK4 requires Î”t < 2Ï€/Ï‰ for stability (very small timesteps!)
- For kz=10 and v_A=1: Î”t < 0.6
- Wasteful for slow nonlinear dynamics (Ï„_nl ~ 1/kâŠ¥vâŠ¥ >> Ï„_A)

### Integrating Factor Method

**Idea:** Treat linear term **exactly**, only approximate nonlinear term.

**Derivation:** Rewrite equation as:
```
âˆ‚zÂ±/âˆ‚t = Â±iÂ·kzÂ·zÂ± + NÂ±
```

Multiply by integrating factor exp(âˆ“iÂ·kzÂ·t):
```
âˆ‚/âˆ‚t [zÂ± Â· exp(âˆ“iÂ·kzÂ·t)] = NÂ± Â· exp(âˆ“iÂ·kzÂ·t)
```

**Solution:**
```
zÂ±(t+Î”t) = exp(Â±iÂ·kzÂ·Î”t) Â· [zÂ±(t) + âˆ«â‚€^Î”t NÂ±(t') Â· exp(âˆ“iÂ·kzÂ·t') dt']
```

**Interpretation:**
- Factor `exp(Â±iÂ·kzÂ·Î”t)` propagates linear waves **exactly** (no stability restriction!)
- Integral of NÂ± is approximated (e.g., with RK2)

### RK2 (Midpoint Method)

For the nonlinear integral, use 2nd-order Runge-Kutta:

**Note:** The code below is simplified pseudocode for illustration. The actual implementation in `timestepping.py` includes additional details (Hermite moments, collision operators, validation). See source code for complete implementation.

```python
def gandalf_step(state, dt, eta, nu, hyper_r=2, hyper_n=2, force_z_plus=None, force_z_minus=None):
    """Single timestep with GANDALF integrating factor + RK2 (simplified pseudocode)."""

    # 1. Compute RHS at t (stage 1)
    k1_plus = z_plus_rhs(state, grid) + forcing_plus
    k1_minus = z_minus_rhs(state, grid) + forcing_minus

    # 2. Midpoint state (evolve by dt/2 with integrating factor)
    z_plus_mid = apply_integrating_factor(state.z_plus + 0.5*dt*k1_plus, grid, dt/2)
    z_minus_mid = apply_integrating_factor(state.z_minus + 0.5*dt*k1_minus, grid, -dt/2)

    state_mid = KRMHDState(z_plus=z_plus_mid, z_minus=z_minus_mid, ...)

    # 3. Compute RHS at t+dt/2 (stage 2)
    k2_plus = z_plus_rhs(state_mid, grid) + forcing_plus
    k2_minus = z_minus_rhs(state_mid, grid) + forcing_minus

    # 4. Full step (evolve by dt with integrating factor)
    z_plus_new = apply_integrating_factor(state.z_plus + dt*k2_plus, grid, dt)
    z_minus_new = apply_integrating_factor(state.z_minus + dt*k2_minus, grid, -dt)

    # 5. Apply dissipation (exponential factors)
    z_plus_new *= exp(-Î·Â·(kâŠ¥Â²/kâŠ¥Â²_max)^rÂ·dt)
    z_minus_new *= exp(-Î·Â·(kâŠ¥Â²/kâŠ¥Â²_max)^rÂ·dt)

    return KRMHDState(z_plus=z_plus_new, z_minus=z_minus_new, ...)
```

**Accuracy:** 2nd-order in time for nonlinear terms, **exact per timestep for linear propagation** (roundoff accumulates over many steps).

This means AlfvÃ©n waves with any kâˆ¥ propagate with **zero phase speed error per timestep** (analytical integration of linear term). The only approximation is in the nonlinear bracket terms {zâˆ“, âˆ‡Â²zÂ±}, which are O(Î”tÂ²) accurate with RK2.

**Practical consequence:** In validation tests (linear AlfvÃ©n waves), expect:
- **Short-term (1 wave period):** <1% energy drift
- **Long-term (100s of Ï„_A):** <0.01% drift
If you see >10% drift over one period, there's likely a bug, not discretization error accumulation.

**Stability:** CFL condition based on nonlinear advection, NOT wave propagation.

### Integrating Factor Application

```python
def apply_integrating_factor(field, grid, dt, v_A=1.0):
    """Multiply by exp(iÂ·kzÂ·dt) for zâº or exp(-iÂ·kzÂ·dt) for zâ»."""
    phase = 1j * grid.kz * (v_A * dt)
    return field * jnp.exp(phase)
```

**Key insight:** This is just a phase shift in Fourier space (cheap operation).

**For zâº:** exp(+iÂ·kzÂ·v_AÂ·dt) (propagates in +áº‘ direction)
**For zâ»:** exp(-iÂ·kzÂ·v_AÂ·dt) (propagates in -áº‘ direction)

### Why "GANDALF"?

This method was developed in the original Fortran+CUDA GANDALF code and is essential for efficient KRMHD simulations. Without it, timesteps would be 10-100Ã— smaller.

## Hyper-Dissipation

### Motivation

At high resolution, energy cascades to small scales and accumulates at the grid Nyquist scale (spectral pile-up). Need dissipation to remove this energy.

**Standard dissipation** (Î·âˆ‡Â²):
- Damps all scales uniformly
- Removes energy from inertial range (bad!)

**Hyper-dissipation** (Î·âˆ‡^(2r) with r>1):
- Concentrates dissipation at high-k
- Preserves inertial range dynamics

### Normalized Formulation

**Key innovation:** Normalize by k_max to make parameters resolution-independent.

**Resistivity:**
```
exp(-Î· Â· (kâŠ¥Â²/kâŠ¥Â²_max)^r Â· dt)
```

where kâŠ¥Â²_max is evaluated at the 2/3 dealiasing boundary:
```python
idxmax = (grid.Nx - 1) // 3
idymax = (grid.Ny - 1) // 3
k_perp_max_squared = grid.kx[idxmax]**2 + grid.ky[idymax]**2
```

**Advantages:**
- **Resolution-independent constraint:** Î·Â·dt < 50 (same for 64Â³, 128Â³, 256Â³!)
- **Practical range:** Î· ~ 0.5-2.0 (matching thesis)
- **High-order safe:** r=4, r=8 satisfy overflow constraint at ANY resolution

**Hyper-collisions** (for Hermite moments):
```
exp(-Î½ Â· (m/M)^(2n) Â· dt)
```

Normalized by M (maximum moment index).

### Parameter Selection

| Order | Description | Stability | Use case |
|-------|-------------|-----------|----------|
| r=1 | Standard dissipation | âœ… Stable | Reference, linear tests |
| r=2 | Moderate hyper | âœ… Stable (validated 32Â³-128Â³) | **Recommended** for production |
| r=4 | Thesis value | âš ï¸ Unstable at 64Â³ forced turbulence | Use with caution ([Issue #82](running_simulations.md#important-parameter-selection)) |
| r=8 | Maximum thesis | â“ Stability TBD | Experimental |

**Overflow constraint:**
```
Î·Â·dt < 50   (safe)
Î·Â·dt < 20   (conservative, warning issued)
```

Code automatically validates and throws `ValueError` if violated.

**Typical values:**
- 32Â³: Î·=1.0, r=2
- 64Â³: Î·=20.0, r=2 (anomalous, under investigation) OR Î·=2.0 with amplitude=0.01
- 128Â³: Î·=2.0, r=2

See [Running Simulations](running_simulations.md) for forced turbulence parameter selection.

### Implementation

Applied as multiplicative factor after timestepping:

```python
# Compute dissipation factor
factor = jnp.exp(-eta * (grid.k_perp_squared / k_perp_max_squared)**hyper_r * dt)

# Apply to Elsasser variables
z_plus_new = z_plus_new * factor
z_minus_new = z_minus_new * factor

# Same for Hermite moments (with m/M normalization)
```

**Energy decay:**
```
E(t) = Eâ‚€ Â· exp(-2Î·âŸ¨(kâŠ¥Â²/kâŠ¥Â²_max)^râŸ©Â·t)
```

where âŸ¨Â·âŸ© is spectrum-weighted average.

## Hermite Moment Expansion

### Velocity-Space Representation

KRMHD captures kinetic physics by expanding the distribution function in **Hermite polynomials**:

```
g(x,y,z,vâˆ¥,t) = Î£ gâ‚˜(x,y,z,t) Â· Hâ‚˜(vâˆ¥/v_th)
```

where Hâ‚˜ are **orthonormal Hermite functions** (quantum harmonic oscillator eigenfunctions):

```
Hâ‚˜(Î¾) = (Ï€^(1/4) âˆš(2^m m!))^(-1) Â· exp(-Î¾Â²/2) Â· Hâ‚˜(Î¾)
```

**Hermite polynomials:**
- Hâ‚€ = 1
- Hâ‚ = 2Î¾
- Hâ‚‚ = 4Î¾Â² - 2
- Hâ‚ƒ = 8Î¾Â³ - 12Î¾
- Recurrence: Hâ‚˜â‚Šâ‚ = 2Î¾Hâ‚˜ - 2mÂ·Hâ‚˜â‚‹â‚

**Moments gâ‚˜:** Fourier-space coefficients of velocity-space expansion.

### Moment Hierarchy

Evolution equations couple moments:

```
âˆ‚gâ‚€/âˆ‚t = {Ï†,gâ‚€} - âˆš2Â·kâˆ¥Â·Re[gâ‚]

âˆ‚gâ‚/âˆ‚t = {Ï†,gâ‚} + (1-1/Î›)Â·âˆ‡âˆ¥Ï†Â·gâ‚€ - kâˆ¥Â·âˆš2Â·gâ‚€ - âˆš2Â·kâˆ¥Â·gâ‚‚ + field line advection

âˆ‚gâ‚˜/âˆ‚t = {Ï†,gâ‚˜} - kâˆ¥Â·âˆš(m)Â·gâ‚˜â‚‹â‚ - kâˆ¥Â·âˆš(m+1)Â·gâ‚˜â‚Šâ‚ + field line advection  (m â‰¥ 2)
```

**Coupling:**
- Perpendicular advection: {Ï†,gâ‚˜} (Poisson bracket)
- Parallel streaming: kâˆ¥Â·âˆšmÂ·gâ‚˜â‚‹â‚ + kâˆ¥Â·âˆš(m+1)Â·gâ‚˜â‚Šâ‚ (wave propagation in vâˆ¥)
- Field line advection: Along curved field lines (mixing of kâˆ¥)

**Truncation:** In practice, keep M moments (e.g., M=8):
- m=0: Density perturbation
- m=1: Parallel flow
- m â‰¥ 2: Higher velocity moments (phase mixing, Landau damping)

**Closure:** Assume gâ‚˜â‚Šâ‚ = 0 (simplest) or use more sophisticated closures.

### Collisions

Lenard-Bernstein collision operator:

```
C[gâ‚˜] = -Î½â‚˜Â·gâ‚˜
```

with Î½â‚˜ = Î½Â·m (m-dependent damping rate).

**Conservation:**
- m=0 (particles): Î½â‚€ = 0 (conserved)
- m=1 (momentum): Î½â‚ = 0 (conserved)
- m â‰¥ 2: Damped exponentially

**Hyper-collisions:** Generalize to Î½â‚˜ = Î½Â·(m/M)^(2n) with n â‰¥ 1.

**Implementation:** Applied as exponential factor (same as resistivity):

```python
# Only damp m â‰¥ 2
for m in range(2, M+1):
    damping_factor = jnp.exp(-nu * (m/M)**(2*hyper_n) * dt)
    g_moments[m] = g_moments[m] * damping_factor
```

### Energy in Velocity Space

Energy distributed across moments:

```
E_m = âˆ« |gâ‚˜(k)|Â² dk
```

**Expected behavior:**
- Phase mixing (collisionless): E_m ~ m^(-3/2)
- Phase unmixing (Landau resonance): E_m ~ m^(-1/2)

**Convergence check:**
```python
from krmhd.diagnostics import hermite_moment_energy

E_m = hermite_moment_energy(state, grid)
ratio = E_m[-1] / E_m[0]  # Should be < 0.1 for converged
```

If ratio > 0.1, increase M (more moments needed).

## CFL Condition and Timestep Selection

### CFL Constraint

For explicit timestepping, the **Courant-Friedrichs-Lewy (CFL)** condition must be satisfied:

```
CFL = max(|vâŠ¥|) Â· dt / dx < 1
```

where:
- `|vâŠ¥|` = maximum perpendicular velocity
- `dt` = timestep
- `dx` = grid spacing (smallest of dx, dy, dz)

**Physical meaning:** Fluid should not cross more than one grid cell per timestep.

**For KRMHD:** Perpendicular velocity comes from stream function:
```
vâŠ¥ ~ |âˆ‡Ï†| ~ kâŠ¥|Ï†|
```

### Automatic Timestep Calculation

```python
from krmhd.timestepping import compute_cfl_timestep

dt_safe = compute_cfl_timestep(state, grid, cfl_safety_factor=0.5)
```

**Algorithm:**
1. Compute Ï† = (zâº + zâ»)/2
2. Estimate max velocity: v_max ~ k_typical Â· max(|Ï†|)
3. Compute dx_min = min(Lx/Nx, Ly/Ny, Lz/Nz)
4. Return dt = cfl_safety_factor Â· dx_min / v_max

**Safety factor:** Typically 0.5 (conservative) to 0.8 (aggressive).

**Note:** GANDALF integrating factor removes linear wave CFL constraint (only nonlinear advection matters).

### Typical Timesteps

| Resolution | Box size | Typical dt | Steps per Ï„_A |
|------------|----------|-----------|---------------|
| 32Â³ | 2Ï€ | 0.01-0.02 | 50-100 |
| 64Â³ | 2Ï€ | 0.005-0.01 | 100-200 |
| 128Â³ | 2Ï€ | 0.0025-0.005 | 200-400 |

For forced turbulence with moderate amplitude, dt ~ 0.005 is typical.

## Memory and Performance

### Memory Scaling

Storage for one complex 3D field:
```
Memory = Nz Ã— Ny Ã— (Nx//2+1) Ã— 16 bytes (complex128)
```

**Examples:**
- 64Â³: 64 Ã— 64 Ã— 33 Ã— 16 = 2.1 MB per field
- 128Â³: 128 Ã— 128 Ã— 65 Ã— 16 = 17 MB per field
- 256Â³: 256 Ã— 256 Ã— 129 Ã— 16 = 135 MB per field

**Total state:**
- 2 Elsasser variables (zÂ±): 2 Ã— 17 MB = 34 MB (128Â³)
- 1 slow mode (Bâˆ¥): 17 MB
- M=8 Hermite moments: 8 Ã— 17 MB = 136 MB
- **Total ~ 187 MB** for 128Â³ (fits in GPU memory easily)

For 256Â³: ~ 1.5 GB (still manageable on modern GPUs).

### Computational Cost

**FFTs dominate:** Each timestep requires:
- ~6 FFTs for Elsasser RHS (forward + backward for each Poisson bracket term)
- ~3M FFTs for Hermite moments
- Total: ~30 FFTs/step for M=8

**FFT cost:** O(NÂ³ log N) per 3D FFT

**Rough scaling:**
- 64Â³: ~0.01 s/step (M1 Pro)
- 128Â³: ~0.1 s/step (8Ã— slower, expect 8Â³/64Â³ Ã— log(128)/log(64) â‰ˆ 9Ã—)
- 256Â³: ~1 s/step (estimated)

**For 50 Ï„_A at 128Â³ with dt=0.005:**
- Steps: 50 / 0.005 = 10,000
- Time: 10,000 Ã— 0.1 s = 1000 s â‰ˆ 17 minutes âœ“ (matches observed)

### Detailed Performance Benchmarks

**Benchmark suite:** `tests/test_performance.py` provides comprehensive performance measurements.

Run benchmarks on your system:
```bash
# All benchmarks with detailed output
pytest tests/test_performance.py -v -s

# Or run directly
python tests/test_performance.py
```

#### Baseline Performance (M1 Pro, JAX 0.4.20 with Metal)

The Poisson bracket operator is the computational bottleneck (6+ calls per timestep). Measured performance:

**3D Poisson Bracket (primary use case):**

| Resolution | Time/call | Throughput | Memory/field |
|------------|-----------|------------|--------------|
| 32Â³        | 0.57 ms   | 1770 calls/sec | 0.3 MB |
| 64Â³        | 3.46 ms   | 289 calls/sec  | 2.1 MB |
| 128Â³       | 28.2 ms   | 35.5 calls/sec | 17.0 MB |
| 256Â³       | 257 ms    | 3.9 calls/sec  | 135 MB |

**2D Poisson Bracket (reference):**

| Resolution | Time/call | Throughput | Memory/field |
|------------|-----------|------------|--------------|
| 64Â²        | 0.11 ms   | 9100 calls/sec | 0.03 MB |
| 128Â²       | 0.21 ms   | 4700 calls/sec | 0.13 MB |
| 256Â²       | 0.85 ms   | 1170 calls/sec | 0.52 MB |
| 512Â²       | 3.15 ms   | 317 calls/sec  | 2.10 MB |

**Realistic Workload Estimates (128Â³ with 6 brackets/timestep):**
- Time per timestep: ~190 ms
- Throughput: ~5.3 timesteps/second
- **1K steps**: ~3.2 minutes
- **100K steps**: ~5.3 hours (typical long simulation)

#### Scaling Analysis

![Performance Scaling](figures/performance_scaling.png)

**Key observations:**
1. **Scaling efficiency**: 3D implementation shows ~0.6Ã— theoretical O(NÂ³ log N) scaling
   - Better-than-expected performance due to efficient JAX/Metal implementation
   - Remains consistent from 32Â³ to 128Â³ (good scalability)

2. **Practical resolution range**: 64Â³ to 128Â³ optimal for development
   - 64Â³: ~3.5 ms/call, fast iteration (~minutes per simulation)
   - 128Â³: ~28 ms/call, production quality (~hours per simulation)
   - 256Â³: ~257 ms/call, high-resolution (~days per simulation)

3. **Memory efficiency**: rfft format saves ~50% compared to full complex storage
   - 128Â³: 17 MB per field (fits easily in GPU memory)
   - 256Â³: 135 MB per field (total state ~1.5 GB, manageable)

4. **Throughput**: Decreases super-linearly with resolution
   - 32Â³: 1770 calls/sec â†’ suitable for rapid prototyping
   - 128Â³: 35.5 calls/sec â†’ standard production runs
   - 256Â³: 3.9 calls/sec â†’ high-resolution campaigns

**Generate plots for your system:**
```bash
# Run benchmarks to collect data
pytest tests/test_performance.py -v -s > my_benchmarks.txt

# Generate scaling plots
python scripts/plot_performance_scaling.py
```

**Platform comparison:**
These benchmarks are specific to M1 Pro with JAX-Metal. Performance will vary on:
- **CUDA GPUs**: Typically 2-5Ã— faster for large grids (256Â³+)
- **CPU-only**: ~10-50Ã— slower (not recommended for production)
- **M1/M2 Max/Ultra**: Similar per-core, but can run multiple simulations in parallel

#### Catastrophic Failure Detection

The benchmark suite includes sanity checks to catch catastrophic failures:
- Fails if 128Â³ takes > 30 seconds/call (1000Ã— slower than expected)
- Warns if compilation takes > 60 seconds

**Note**: These thresholds detect major breakage, not typical performance regressions (2-5Ã— slowdowns).
For true regression detection, compare against baseline data or integrate with CI performance tracking.

To customize thresholds or add stricter regression checks, modify `test_performance.py`.

### Optimization Tips

1. **Use JIT compilation:**
   ```python
   from jax import jit

   @jit
   def step_function(state):
       return gandalf_step(state, dt=0.005, eta=1.0)
   ```

2. **Reduce resolution for testing:**
   - 32Â³ for quick tests (seconds)
   - 64Â³ for parameter scans (minutes)
   - 128Â³+ for production (hours)

3. **Use float32 instead of float64:**
   ```bash
   JAX_ENABLE_X64=0 uv run python examples/forcing_minimal.py
   # Warning: May affect energy conservation accuracy (especially in inviscid runs)
   ```
   Saves memory and ~2Ã— faster, but less accurate. Not recommended for production runs where energy conservation is critical.

4. **Profile to find bottlenecks:**
   ```python
   import jax
   jax.profiler.start_trace("/tmp/jax_trace")
   # Run simulation
   jax.profiler.stop_trace()
   ```

## Validation and Testing

GANDALF includes extensive tests (285+ passing, including 10 performance benchmarks):

```bash
# Run all tests
uv run pytest tests/

# Specific modules
uv run pytest tests/test_spectral.py      # Spectral operations
uv run pytest tests/test_physics.py       # Poisson bracket, RHS
uv run pytest tests/test_timestepping.py  # Integrating factor, convergence
uv run pytest tests/test_hermite.py       # Hermite basis
uv run pytest tests/test_diagnostics.py   # Spectra, energy
```

**Key validation tests:**

1. **Derivative accuracy:** Compare spectral derivatives to analytical
   - **Expected accuracy:** ~10â»âµ (FFT roundoff after real-space roundtrip)
   - Validates that âˆ‚/âˆ‚x â†” iÂ·kx works correctly
   - See `test_spectral.py:189` for reference tolerance

2. **Dealiasing effectiveness:** Check energy conservation without/with dealiasing
   - **Without dealiasing:** Spurious energy growth (simulation blows up)
   - **With dealiasing:** Energy conserved to <0.01% (inviscid limit)

3. **AlfvÃ©n wave dispersion:** Ï‰ = kâˆ¥v_A (linear physics)
   - **Expected accuracy:** <1% energy drift over one wave period (short-term test)
   - Tests validate spectral derivatives + integrating factor correctness
   - **Drift >10% indicates a bug**, not normal accumulation
   - See `test_timestepping.py:369` for reference: <1% over full period

4. **Energy conservation:** Long-term inviscid evolution (Î·=0, Î½=0)
   - **Short-term (1 period):** <1% energy drift (see test #3 above)
   - **Long-term (100s of Ï„_A):** <0.01% cumulative drift
   - Energy balance typically conserved to ~10â»Â¹â° relative error
   - Validates analytical linear propagation and Poisson bracket implementation
   - With dissipation: Exponential decay E(t) = Eâ‚€Â·exp(-2Î·âŸ¨kâŠ¥Â²âŸ©t)

5. **Convergence order:** 2nd-order in time for RK2
   - Error ~ Î”tÂ² for nonlinear terms (doubling Î”t â†’ 4Ã— error)
   - Linear terms: Minimal timestep-independent error (analytical integration!)

6. **Hermite orthogonality:** âˆ« Hâ‚˜ Hâ‚™ = Î´â‚˜â‚™
   - **Expected accuracy:** ~10â»Â¹â´ (numerical quadrature + roundoff)
   - Validates velocity-space basis implementation

**Benchmark examples:**
- `orszag_tang.py`: Nonlinear MHD benchmark
- `alfvenic_cascade_benchmark.py`: kâŠ¥^(-5/3) turbulent spectrum
- `kinetic_fdt_validation.py`: Landau damping rates

## Summary

| Component | Implementation | Key Parameters |
|-----------|---------------|----------------|
| **Spatial** | 3D Fourier (rfft) | Nx, Ny, Nz, Lx, Ly, Lz |
| **Dealiasing** | 2/3 rule | k_max = (2/3)Â·k_Nyquist |
| **Time** | GANDALF + RK2 | dt (CFL-limited) |
| **Dissipation** | Normalized hyper | Î·, r (typically Î·=1-2, r=2) |
| **Kinetic** | Hermite moments | M (typically 8), Î½, n |
| **Poisson** | Direct (k-space) | Exact solve |

**Strengths:**
- Spectral accuracy
- Exact linear propagation
- Resolution-independent parameters
- Energy conservation (inviscid limit)

**Limitations:**
- Periodic boundaries only
- Memory intensive (global modes)
- CFL constraint on nonlinear terms

## Further Reading

- **Spectral Methods:** Boyd (2001), "Chebyshev and Fourier Spectral Methods"
- **Integrating Factor:** Cox & Matthews (2002), J. Comp. Phys. 176:430
- **GANDALF Method:** Original thesis (see `gandalf_thesis_chapter.pdf`)
- **Hermite Expansion:** Grad (1949), Comm. Pure Appl. Math. 2:331

For practical usage:
- [Running Simulations](running_simulations.md) - Examples and workflows
- [Parameter Scans](parameter_scans.md) - Systematic studies
- [Physics Validity](physics_validity.md) - When to trust results
